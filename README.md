# Street_Fighter_PPO

## Demo videos of the partially trained model:

### Guile
https://user-images.githubusercontent.com/67729558/210306417-2c7bd7f1-0f08-4a17-b8fd-bc9e785c2020.mp4

### Ken
https://user-images.githubusercontent.com/67729558/210306136-ea12569c-5a44-4fc4-a30f-f23e21466a66.mp4

### Chun Li
https://user-images.githubusercontent.com/67729558/210304483-f51fe2bc-4df7-448d-ae09-51f81feaed21.mp4

### Zangief
https://user-images.githubusercontent.com/67729558/210307168-5c1a607f-8550-40de-a174-d8ca7f3b26aa.mp4

https://user-images.githubusercontent.com/67729558/210307294-4c067966-c34c-480e-8a2f-e2a3f5009a26.mp4

### Dhalsim
https://user-images.githubusercontent.com/67729558/210306855-4d8077d9-16c4-4098-b3c2-8d7d483da1e1.mp4

https://user-images.githubusercontent.com/67729558/210307062-0a0fa611-5f7a-42a3-94a6-31cd02fedb2e.mp4


Trained a PPO agent to play Street Fighter 2 using Stable Baselines 3, Optuna, and PyTorch
- HINT: make sure that you using the street-fighter virtual environment specified by using the command 'source street-figher/bin/activate'

### To view the logging data 
- Navigate into the logs folder (cd logs)
- use command 'tensorboard --logdir=.'
- Then open the localhost link provided by tensorboard
